{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "CAPSTONE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HouB5dVjY2IM"
      },
      "source": [
        "from __future__ import division\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "#readingsourcefile\n",
        "filename = \"attack\"\n",
        "df = pd.read_csv(filename, sep =',' , header = None, error_bad_lines = False)\n",
        "# removing first row of data then sorting according to time field\n",
        "array = df.to_numpy()\n",
        "#removing protocol column\n",
        "arr = np.delete(array, 5, axis=0)\n",
        "arr = np.delete(array, 0, axis=0)\n",
        "array = sorted(arr, key=lambda x: float(x[1]))\n",
        "array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHfO7sZ6Z3bz"
      },
      "source": [
        "# storing each packet's transmission duration\n",
        "packetDurations = []\n",
        "# naming values of info field\n",
        "infoList = ['RPL Control (Destination Advertisement Object)',\n",
        "'RPL Control (DODAG Information Solicitation)',\n",
        "'RPL Control (DODAG Information Object)', 'Ack',\n",
        "'PDUType: 108 t Unknown',\n",
        "'PDUType: 112 t Unknown',\n",
        "'3000 > 3001 Len=11']\n",
        "infoDict = {}\n",
        "index = 1\n",
        "for info in infoList:\n",
        "  infoDict[info] = index\n",
        "  index += 1\n",
        "#print(infoDict)\n",
        "# storing malicious nodes\n",
        "labelNodes = []\n",
        "# rewriting source, destination and info columns #\n",
        "counter = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcMw1h0uaNj5"
      },
      "source": [
        "counter = 0\n",
        "while(counter < len(array)):\n",
        "  src = array[counter][2]\n",
        "  dst = array[counter][3]\n",
        "  array[counter][2] = int(src.split(\":\").pop(), 16) if not pd.isnull(src) else src\n",
        "  if(dst == 'ff02::1a'):\n",
        "    array[counter][3] = int(9999) if not pd.isnull(dst) else dst\n",
        "  else:\n",
        "    array[counter][3] = int(dst.split(\":\").pop(), 16) if not pd.isnull(dst) else dst\n",
        "  if array[counter][6] in infoDict:\n",
        "    array[counter][6] = infoDict[array[counter][6]]\n",
        "  else:\n",
        "    array[counter][6]=None\n",
        "  if counter != 0 and counter + 1 < len(array):\n",
        "    duration = float(array[counter][1]) - float(array[counter - 1][1])\n",
        "    packetDurations.append([math.floor(float(array[counter][1])),array[counter][2],array[counter][3], duration])\n",
        "\n",
        "  counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5TllZasd-Ft",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "fcb96ff4-0e1c-4b83-deab-32b0e26a48fd"
      },
      "source": [
        "# Calculating node counts in per seconds #\n",
        "currentSecond = 0.0\n",
        "lastSecond = math.floor(float(array[-1][1]))\n",
        "packetsInEachSecond = dict()\n",
        "while currentSecond <= lastSecond:\n",
        "  currentSecondArray = []\n",
        "  currentRow = 1\n",
        "  while currentRow < len(array):\n",
        "    currentPacketSecond = floor(float(array[currentRow][1]))\n",
        "    if currentPacketSecond == currentSecond:\n",
        "      currentSecondArray.append(array[currentRow])\n",
        "    currentRow += 1\n",
        "  packetsInEachSecond[currentSecond] = currentSecondArray\n",
        "  currentSecond += 1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8c6ebcf67bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculating node counts in per seconds #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcurrentSecond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlastSecond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpacketsInEachSecond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcurrentSecond\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlastSecond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vItbdymKhM8Q"
      },
      "source": [
        "# Calculating control packet counts in per seconds #\n",
        "sourceCountsBySeconds = dict()\n",
        "destinationCountsBySeconds =dict()\n",
        "daoCountsBySeconds =dict()\n",
        "disCountsBySeconds =dict()\n",
        "dioCountsBySeconds =dict()\n",
        "totalDaoDisDioBySecond =dict()\n",
        "for sec in packetsInEachSecond:\n",
        "  sourceNodeCounts = dict()\n",
        "  destinationNodeCounts =dict()\n",
        "  daoCountsByNode =dict()\n",
        "  disCountsByNode =dict()\n",
        "  dioCountsByNode =dict()\n",
        "  for packet in packetsInEachSecond[sec]:\n",
        "    src = packet[2]\n",
        "    dst = packet[3]\n",
        "    info = packet[5]\n",
        "    sourceNodeCounts[src] = 1 if src not in sourceNodeCounts else sourceNodeCounts[src] + 1\n",
        "    destinationNodeCounts[dst] = 1 if dst not in destinationNodeCounts else destinationNodeCounts[dst] + 1\n",
        "    if info == 1:\n",
        "      daoCountsByNode[src] = 1 if src not in daoCountsByNode else daoCountsByNode[src] + 1\n",
        "    elif info == 2:\n",
        "      disCountsByNode[src] = 1 if src not in disCountsByNode else disCountsByNode[src] + 1\n",
        "    elif info == 3:\n",
        "      dioCountsByNode[src] = 1 if src not in dioCountsByNode else dioCountsByNode[src] + 1\n",
        "    if info == 1 or 2 or 3\n",
        "      totalDaoDisDioBySecond[sec] = 1 if sec not in totalDaoDisDioBySecond else totalDaoDisDioBySecond[sec] + 1\n",
        "  sourceCountsBySeconds[sec] = sourceNodeCounts\n",
        "  destinationCountsBySeconds[sec] = destinationNodeCounts\n",
        "  daoCountsBySeconds[sec] = daoCountsByNode\n",
        "  disCountsBySeconds[sec] = disCountsByNode\n",
        "  dioCountsBySeconds[sec] = dioCountsByNode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGJ6XhktxppS"
      },
      "source": [
        "# Calculating total duration times by seconds #\n",
        "transTotalDurBySec =dict()\n",
        "for sec in sourceCountsBySeconds:\n",
        "  transTotalDurBySec[sec] =dict()\n",
        "  for node in sourceCountsBySeconds[sec]:\n",
        "    transTotalDurBySec[sec][node] = 0\n",
        "rcvTotalDurBySec =dict()\n",
        "for sec in destinationCountsBySeconds:\n",
        "  rcvTotalDurBySec[sec] =dict()\n",
        "  for node in destinationCountsBySeconds[sec]:\n",
        "    rcvTotalDurBySec[sec][node] = 0\n",
        "counter = 1\n",
        "while counter < len(packetDurations):\n",
        "  second = packetDurations[counter][0]\n",
        "  try:\n",
        "    nodeTr = packetDurations[counter][1]\n",
        "    nodeRcv = packetDurations[counter][2]\n",
        "    transTotalDurBySec[second][nodeTr] = transTotalDurBySec[second][nodeTr] + packetDurations[counter][3]\n",
        "    rcvTotalDurBySec[second][nodeRcv] = rcvTotalDurBySec[second][nodeRcv] + packetDurations[counter][3]\n",
        "  except:\n",
        "    print(\"This is an error message!\")\n",
        "  counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khxu04Pqy3GS"
      },
      "source": [
        "# Creating enriched IoT dataset file #\n",
        "monitorArray = []\n",
        "counter = 0\n",
        "labelCounter = 0\n",
        "while counter < len(array):\n",
        "  if not pd.isnull(array[counter][2]):\n",
        "    src = array[counter][2]\n",
        "    dst = array[counter][3]\n",
        "    row = array[counter]\n",
        "    second = floor(float(array[counter][1]))\n",
        "    srcCount = 0.0\n",
        "    dstCount = 0.0\n",
        "    if second in sourceCountsBySeconds:\n",
        "      srcCounts = sourceCountsBySeconds[second]\n",
        "      if src in srcCounts:\n",
        "        srcCount = srcCounts[src]\n",
        "    if second in destinationCountsBySeconds:\n",
        "      dstCounts = destinationCountsBySeconds[second]\n",
        "      if dst in dstCounts:\n",
        "        dstCount = dstCounts[dst]\n",
        "    transmissionRate = srcCount / 1000.0\n",
        "    receptionRate = dstCount / 1000.0\n",
        "    TrRr = transmissionRate / receptionRate if receptionRate != 0 else 0\n",
        "    trnTtlDur = transTotalDurBySec[second][src]\n",
        "    rcvTtlDur = rcvTotalDurBySec[second][dst]\n",
        "    trnAverageTime = trnTtlDur / srcCount\n",
        "    rcvAverageTime = rcvTtlDur / dstCount\n",
        "    daoSrcCount = 0\n",
        "    disSrcCount = 0\n",
        "    dioSrcCount = 0\n",
        "    if len(daoCountsBySeconds[second]) > 0 and src in daoCountsBySeconds[second]:\n",
        "      daoSrcCount = daoCountsBySeconds[second][src]\n",
        "    else:\n",
        "      daoSrcCount = 0\n",
        "    if len(disCountsBySeconds[second]) > 0 and src in disCountsBySeconds[second]:\n",
        "      disSrcCount = disCountsBySeconds[second][src]\n",
        "    else:\n",
        "      disSrcCount = 0\n",
        "    if len(dioCountsBySeconds[second]) > 0 and src in dioCountsBySeconds[second]:\n",
        "      dioSrcCount = dioCountsBySeconds[second][src]\n",
        "    else:\n",
        "      dioSrcCount = 0\n",
        "    dao = daoSrcCount\n",
        "    dis = disSrcCount\n",
        "    dio = dioSrcCount\n",
        "    label = 1\n",
        "    row = np.append(row, str(transmissionRate))\n",
        "    row = np.append(row, str(receptionRate))\n",
        "    row = np.append(row, str(TrRr))\n",
        "    row = np.append(row, str(srcCount))\n",
        "    row = np.append(row, str(dstCount))\n",
        "    row = np.append(row, str(trnTtlDur))\n",
        "    row = np.append(row, str(rcvTtlDur))\n",
        "    row = np.append(row, str(trnAverageTime))\n",
        "    row = np.append(row, str(rcvAverageTime))\n",
        "    row = np.append(row, str(dao))\n",
        "    row = np.append(row, str(dis))\n",
        "    row = np.append(row, str(dio))\n",
        "    row = np.append(row, str(label))\n",
        "    monitorArray.append(row)\n",
        "  counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pKV9Y5Uz9b-"
      },
      "source": [
        "headers = ['No.', 'Time', 'Source', 'Destination', 'Length', 'Info',\n",
        "'Transmission Rate (per 1000 ms)',\n",
        "'Reception Rate (per 1000 ms)',\n",
        "'TR / RR',\n",
        "'Sources Count Per Sec',\n",
        "'Destinations Count Per Sec',\n",
        "'Trans Total Duration Per Sec',\n",
        "'Rcv Total Duration Per Sec',\n",
        "'Trans Average Per Sec',\n",
        "'Rcv Average Per Sec',\n",
        "'DAO',\n",
        "'DIS',\n",
        "'DIO',\n",
        "'Label'\n",
        "]\n",
        "monitorArray.insert(0, headers)\n",
        "with open('result.csv', 'w') as monitoring:\n",
        "  wr = csv.writer(monitoring, dialect='excel', delimiter=',')\n",
        "  wr.writerows(monitorArray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR4pV5Vq01qi"
      },
      "source": [
        "##########################################\n",
        "##########################################\n",
        "# Script 2 - Data Normalization Algorithm #\n",
        "##########################################\n",
        "# import the required packages\n",
        "#import pandas as pd\n",
        "#...\n",
        "# dataset headers\n",
        "#path1='./csvs/'\n",
        "headers_val = [\n",
        "'Length', 'Info',\n",
        "'Transmission Rate (per 1000 ms)',\n",
        "'Reception Rate (per 1000 ms)',\n",
        "'TR / RR',\n",
        "'Sources Count Per Sec',\n",
        "'Destinations Count Per Sec',\n",
        "'Trans Total Duration Per Sec',\n",
        "'Rcv Total Duration Per Sec',\n",
        "'Trans Average Per Sec',\n",
        "'Rcv Average Per Sec',\n",
        "'DAO',\n",
        "'DIS',\n",
        "'DIO'\n",
        "]\n",
        "amgPd = pd.DataFrame()\n",
        "# import dataset\n",
        "for chunk in pd.read_csv('result.csv', chunksize = 250000, low_memory=False):\n",
        "  amgPd = pd.concat([amgPd,chunk])\n",
        "print ('result')\n",
        "print (amgPd.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PL-FAp0y15wq"
      },
      "source": [
        "# transform matrix format\n",
        "A = amgPd.as_matrix()\n",
        "row_num = A.shape[1]\n",
        "X = A[:, 0:row_num - 1]\n",
        "Y = A[:, row_num - 1].astype(int)\n",
        "# feature normalization #\n",
        "X = preprocessing.quantile_transform (X, output_distribution='normal')\n",
        "X = preprocessing.minmax_scale (X)\n",
        "data = pd.DataFrame(X, columns=headers_val)\n",
        "labels = pd.DataFrame(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKRxo2gw1755"
      },
      "source": [
        "# creating main dataset #\n",
        "amgPd = data.join(labels.rename(columns=0:'Label'))\n",
        "print ('BH1000%5mix after scaling')\n",
        "print (amgPd.describe())\n",
        "# transform to csv of normalized dataset\n",
        "amgPd.to_csv('BH1000%5mix_norm.csv', index=False)\n",
        "# import another dataset\n",
        "amgPd1 = pd.DataFrame()\n",
        "for chunk in pd.read_csv(path1+'BH100%10mix.csv', chunksize = 250000, low_memory=False):\n",
        "  amgPd1 = pd.concat([amgPd1,chunk])\n",
        "amgPd1.drop([u'No.','Time', u'Source', u'Destination'], axis=1, inplace=True)\n",
        "print ('BH100%10')\n",
        "print (amgPd1.describe())\n",
        "# transform matrix format\n",
        "A = amgPd1.as_matrix()\n",
        "row_num = A.shape[1]\n",
        "X = A[:, 0:row_num - 1]\n",
        "Y = A[:, row_num - 1].astype(int)\n",
        "# feature normalization #\n",
        "X = preprocessing.quantile_transform (X, output_distribution='normal')\n",
        "X = preprocessing.minmax_scale (X)\n",
        "data = pd.DataFrame(X, columns=headers_val)\n",
        "labels = pd.DataFrame(Y)\n",
        "# concatenating the datasets #\n",
        "amgPd1 = data.join(labels.rename(columns=0:'Label'))\n",
        "print ('BH100%10 after scaling')\n",
        "print (amgPd1.describe())\n",
        "amgPd1.to_csv('BH100%10mix_norm.csv', index=False)\n",
        "# appending to main dataset\n",
        "amgPd = pd.concat ([amgPd, amgPd1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}